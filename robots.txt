# Robots.txt for HelixPHP Website
# https://helixphp.github.io/website/

# Allow all crawlers
User-agent: *
Allow: /

# Optimize crawl rate
Crawl-delay: 1

# Sitemap location
Sitemap: https://helixphp.github.io/website/sitemap.xml

# Disallow temporary or build files
Disallow: /.git/
Disallow: /_site/
Disallow: /.jekyll-cache/
Disallow: /vendor/
Disallow: /node_modules/
Disallow: *.log
Disallow: .DS_Store

# Allow search engines to index everything else
Allow: /assets/
Allow: /docs/
Allow: /pt/

# Specific bot rules
User-agent: Googlebot
Allow: /

User-agent: Bingbot
Allow: /

User-agent: Slurp
Allow: /

User-agent: DuckDuckBot
Allow: /

User-agent: Baiduspider
Allow: /

User-agent: facebookexternalhit
Allow: /

User-agent: Twitterbot
Allow: /

User-agent: LinkedInBot
Allow: /

User-agent: WhatsApp
Allow: /

User-agent: Slack
Allow: /